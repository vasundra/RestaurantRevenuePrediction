{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# To upload our datasets from our working directory we need to mount our drive contents to the colab environment. \n",
        "# For the code to do so you can search “mount” in code snippets or use the code given below. \n",
        "# Our entire drive contents are now mounted on colab at the location “/gdrive”.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "kkuNadU0n9tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7475d6-ad61-4a9e-cc58-611fa4836e72"
      },
      "id": "kkuNadU0n9tX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vecstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbLEmNE6ELyW",
        "outputId": "be509bc0-4d7f-4610-ae26-9957240fc545"
      },
      "id": "TbLEmNE6ELyW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9eaf01",
      "metadata": {
        "id": "ab9eaf01"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score, r2_score\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from vecstack import StackingTransformer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from vecstack import stacking\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2001e09",
      "metadata": {
        "id": "f2001e09",
        "outputId": "02edf496-4601-4c80-9bfc-c1f13042f448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaurant Revenue - Train Data Shape (137, 43)\n",
            "Restaurant Revenue - Test Data Shape (100000, 42)\n",
            "No. of features in train set 43\n",
            "No. of features in test set 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  ...  \\\n",
              "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2  ...   \n",
              "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1  ...   \n",
              "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2  ...   \n",
              "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4  ...   \n",
              "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2  ...   \n",
              "\n",
              "   P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
              "0  3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
              "1  3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
              "2  3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
              "3  7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
              "4  3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a3e2893-6ef2-4859-bece-eeef288b075d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Open Date</th>\n",
              "      <th>City</th>\n",
              "      <th>City Group</th>\n",
              "      <th>Type</th>\n",
              "      <th>P1</th>\n",
              "      <th>P2</th>\n",
              "      <th>P3</th>\n",
              "      <th>P4</th>\n",
              "      <th>P5</th>\n",
              "      <th>...</th>\n",
              "      <th>P29</th>\n",
              "      <th>P30</th>\n",
              "      <th>P31</th>\n",
              "      <th>P32</th>\n",
              "      <th>P33</th>\n",
              "      <th>P34</th>\n",
              "      <th>P35</th>\n",
              "      <th>P36</th>\n",
              "      <th>P37</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>07/17/1999</td>\n",
              "      <td>İstanbul</td>\n",
              "      <td>Big Cities</td>\n",
              "      <td>IL</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5653753.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>02/14/2008</td>\n",
              "      <td>Ankara</td>\n",
              "      <td>Big Cities</td>\n",
              "      <td>FC</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6923131.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>03/09/2013</td>\n",
              "      <td>Diyarbakır</td>\n",
              "      <td>Other</td>\n",
              "      <td>IL</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2055379.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>02/02/2012</td>\n",
              "      <td>Tokat</td>\n",
              "      <td>Other</td>\n",
              "      <td>IL</td>\n",
              "      <td>6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>7.5</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>2675511.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>05/09/2009</td>\n",
              "      <td>Gaziantep</td>\n",
              "      <td>Other</td>\n",
              "      <td>IL</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4316715.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a3e2893-6ef2-4859-bece-eeef288b075d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a3e2893-6ef2-4859-bece-eeef288b075d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a3e2893-6ef2-4859-bece-eeef288b075d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('/gdrive/My Drive/Team_Assignment_1/train.csv')\n",
        "\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Team_Assignment_1/test.csv')\n",
        "test_df_original = test_df.copy()\n",
        "\n",
        "train_columns = list(train_df.columns)\n",
        "\n",
        "\n",
        "print(\"Restaurant Revenue - Train Data Shape\", train_df.shape)\n",
        "print(\"Restaurant Revenue - Test Data Shape\", test_df.shape)\n",
        "\n",
        "print(\"No. of features in train set\", len(train_columns))\n",
        "test_columns = list(test_df.columns)\n",
        "\n",
        "print(\"No. of features in test set\", len(test_columns))\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data Info\n",
        "train_df.info()\n",
        "\n",
        "#Test Data Info\n",
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcKXs5vGGlo1",
        "outputId": "c46fa591-c682-4a51-8fe3-b71d1b0c8e73"
      },
      "id": "WcKXs5vGGlo1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 137 entries, 0 to 136\n",
            "Data columns (total 43 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Id          137 non-null    int64  \n",
            " 1   Open Date   137 non-null    object \n",
            " 2   City        137 non-null    object \n",
            " 3   City Group  137 non-null    object \n",
            " 4   Type        137 non-null    object \n",
            " 5   P1          137 non-null    int64  \n",
            " 6   P2          137 non-null    float64\n",
            " 7   P3          137 non-null    float64\n",
            " 8   P4          137 non-null    float64\n",
            " 9   P5          137 non-null    int64  \n",
            " 10  P6          137 non-null    int64  \n",
            " 11  P7          137 non-null    int64  \n",
            " 12  P8          137 non-null    int64  \n",
            " 13  P9          137 non-null    int64  \n",
            " 14  P10         137 non-null    int64  \n",
            " 15  P11         137 non-null    int64  \n",
            " 16  P12         137 non-null    int64  \n",
            " 17  P13         137 non-null    float64\n",
            " 18  P14         137 non-null    int64  \n",
            " 19  P15         137 non-null    int64  \n",
            " 20  P16         137 non-null    int64  \n",
            " 21  P17         137 non-null    int64  \n",
            " 22  P18         137 non-null    int64  \n",
            " 23  P19         137 non-null    int64  \n",
            " 24  P20         137 non-null    int64  \n",
            " 25  P21         137 non-null    int64  \n",
            " 26  P22         137 non-null    int64  \n",
            " 27  P23         137 non-null    int64  \n",
            " 28  P24         137 non-null    int64  \n",
            " 29  P25         137 non-null    int64  \n",
            " 30  P26         137 non-null    float64\n",
            " 31  P27         137 non-null    float64\n",
            " 32  P28         137 non-null    float64\n",
            " 33  P29         137 non-null    float64\n",
            " 34  P30         137 non-null    int64  \n",
            " 35  P31         137 non-null    int64  \n",
            " 36  P32         137 non-null    int64  \n",
            " 37  P33         137 non-null    int64  \n",
            " 38  P34         137 non-null    int64  \n",
            " 39  P35         137 non-null    int64  \n",
            " 40  P36         137 non-null    int64  \n",
            " 41  P37         137 non-null    int64  \n",
            " 42  revenue     137 non-null    float64\n",
            "dtypes: float64(9), int64(30), object(4)\n",
            "memory usage: 46.1+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 42 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   Id          100000 non-null  int64  \n",
            " 1   Open Date   100000 non-null  object \n",
            " 2   City        100000 non-null  object \n",
            " 3   City Group  100000 non-null  object \n",
            " 4   Type        100000 non-null  object \n",
            " 5   P1          100000 non-null  int64  \n",
            " 6   P2          100000 non-null  float64\n",
            " 7   P3          100000 non-null  float64\n",
            " 8   P4          100000 non-null  float64\n",
            " 9   P5          100000 non-null  int64  \n",
            " 10  P6          100000 non-null  int64  \n",
            " 11  P7          100000 non-null  int64  \n",
            " 12  P8          100000 non-null  int64  \n",
            " 13  P9          100000 non-null  int64  \n",
            " 14  P10         100000 non-null  int64  \n",
            " 15  P11         100000 non-null  int64  \n",
            " 16  P12         100000 non-null  int64  \n",
            " 17  P13         100000 non-null  float64\n",
            " 18  P14         100000 non-null  int64  \n",
            " 19  P15         100000 non-null  int64  \n",
            " 20  P16         100000 non-null  int64  \n",
            " 21  P17         100000 non-null  int64  \n",
            " 22  P18         100000 non-null  int64  \n",
            " 23  P19         100000 non-null  int64  \n",
            " 24  P20         100000 non-null  int64  \n",
            " 25  P21         100000 non-null  int64  \n",
            " 26  P22         100000 non-null  int64  \n",
            " 27  P23         100000 non-null  int64  \n",
            " 28  P24         100000 non-null  int64  \n",
            " 29  P25         100000 non-null  int64  \n",
            " 30  P26         100000 non-null  float64\n",
            " 31  P27         100000 non-null  float64\n",
            " 32  P28         100000 non-null  float64\n",
            " 33  P29         100000 non-null  float64\n",
            " 34  P30         100000 non-null  int64  \n",
            " 35  P31         100000 non-null  int64  \n",
            " 36  P32         100000 non-null  int64  \n",
            " 37  P33         100000 non-null  int64  \n",
            " 38  P34         100000 non-null  int64  \n",
            " 39  P35         100000 non-null  int64  \n",
            " 40  P36         100000 non-null  int64  \n",
            " 41  P37         100000 non-null  int64  \n",
            "dtypes: float64(8), int64(30), object(4)\n",
            "memory usage: 32.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To get list of names of all Columns\n",
        "\n",
        "TrainCols = list(train_df.columns.values)\n",
        "TestCols = list(test_df.columns.values)\n",
        "print(TrainCols)\n",
        "print(TestCols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7c7d4QfM-Fm",
        "outputId": "098f535e-efed-460b-ea61-303aa6c50802"
      },
      "id": "m7c7d4QfM-Fm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Id', 'Open Date', 'City', 'City Group', 'Type', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37', 'revenue']\n",
            "['Id', 'Open Date', 'City', 'City Group', 'Type', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check number of null values in train data\n",
        "train_df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkOcV365HO_k",
        "outputId": "4d626d46-3cbe-43fa-ff5d-21490cb646c0"
      },
      "id": "AkOcV365HO_k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id            0\n",
              "Open Date     0\n",
              "City          0\n",
              "City Group    0\n",
              "Type          0\n",
              "P1            0\n",
              "P2            0\n",
              "P3            0\n",
              "P4            0\n",
              "P5            0\n",
              "P6            0\n",
              "P7            0\n",
              "P8            0\n",
              "P9            0\n",
              "P10           0\n",
              "P11           0\n",
              "P12           0\n",
              "P13           0\n",
              "P14           0\n",
              "P15           0\n",
              "P16           0\n",
              "P17           0\n",
              "P18           0\n",
              "P19           0\n",
              "P20           0\n",
              "P21           0\n",
              "P22           0\n",
              "P23           0\n",
              "P24           0\n",
              "P25           0\n",
              "P26           0\n",
              "P27           0\n",
              "P28           0\n",
              "P29           0\n",
              "P30           0\n",
              "P31           0\n",
              "P32           0\n",
              "P33           0\n",
              "P34           0\n",
              "P35           0\n",
              "P36           0\n",
              "P37           0\n",
              "revenue       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the Open Date Column to the datetime data type\n",
        "train_df['Open Date'] = pd.to_datetime(train_df['Open Date'])\n",
        "\n",
        "# Add seperate columns for the DateTime data types\n",
        "\n",
        "train_df['Opening Day'] = train_df['Open Date'].dt.day\n",
        "train_df['Opening Year'] = train_df['Open Date'].dt.year\n",
        "train_df['Opening Month'] = train_df['Open Date'].dt.month\n",
        "\n",
        "\n",
        "test_df['Open Date'] = pd.to_datetime(test_df['Open Date'])\n",
        "\n",
        "# Add seperate columns for the DateTime data types\n",
        "\n",
        "test_df['Opening Day'] = test_df['Open Date'].dt.day\n",
        "test_df['Opening Year'] = test_df['Open Date'].dt.year\n",
        "test_df['Opening Month'] = test_df['Open Date'].dt.month"
      ],
      "metadata": {
        "id": "576oj0NyN146"
      },
      "id": "576oj0NyN146",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping ID and Revenue Column from Train Data Set\n",
        "train_df = train_df.drop(['Id'], axis=1)\n",
        "test_df = test_df.drop(['Id'], axis=1)\n",
        "\n",
        "Y = train_df['revenue']\n",
        "X = train_df.drop(['revenue'], axis=1)\n",
        "\n",
        "X_Test = test_df;\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waoQ-jwRJTJL",
        "outputId": "01bba1bb-e473-43ca-f991-073f1dbe3fbf"
      },
      "id": "waoQ-jwRJTJL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(137, 44) (137,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Categorical Features\n",
        "categoricalFeatures = ['City', 'City Group', 'Type', 'Opening Day', 'Opening Month', 'Opening Year']"
      ],
      "metadata": {
        "id": "J0pwz9DCM0Qy"
      },
      "id": "J0pwz9DCM0Qy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91fc32c7",
      "metadata": {
        "id": "91fc32c7",
        "outputId": "21b96c79-5299-40e6-f0cf-820b9f8c2049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     P1   P2   P3   P4  P5  P6  P7  P8  P9  P10  ...  x5_2005  x5_2006  \\\n",
              "94    2  3.0  4.0  4.0   2   2   5   5   5    5  ...      0.0      0.0   \n",
              "104   4  5.0  4.0  3.0   1   3   5   5   5    5  ...      0.0      0.0   \n",
              "100   3  5.0  4.0  4.0   2   5   5   5   5    5  ...      0.0      0.0   \n",
              "112   4  5.0  5.0  4.0   1   5   5   5   4    4  ...      0.0      0.0   \n",
              "63    2  2.0  4.0  4.0   3   1   4   5   5    5  ...      0.0      0.0   \n",
              "\n",
              "     x5_2007  x5_2008  x5_2009  x5_2010  x5_2011  x5_2012  x5_2013  x5_2014  \n",
              "94       0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0  \n",
              "104      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
              "100      1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
              "112      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
              "63       0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0  \n",
              "\n",
              "[5 rows x 135 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ce962c9-bc3a-4d3c-b731-5319594e20c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P1</th>\n",
              "      <th>P2</th>\n",
              "      <th>P3</th>\n",
              "      <th>P4</th>\n",
              "      <th>P5</th>\n",
              "      <th>P6</th>\n",
              "      <th>P7</th>\n",
              "      <th>P8</th>\n",
              "      <th>P9</th>\n",
              "      <th>P10</th>\n",
              "      <th>...</th>\n",
              "      <th>x5_2005</th>\n",
              "      <th>x5_2006</th>\n",
              "      <th>x5_2007</th>\n",
              "      <th>x5_2008</th>\n",
              "      <th>x5_2009</th>\n",
              "      <th>x5_2010</th>\n",
              "      <th>x5_2011</th>\n",
              "      <th>x5_2012</th>\n",
              "      <th>x5_2013</th>\n",
              "      <th>x5_2014</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 135 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ce962c9-bc3a-4d3c-b731-5319594e20c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ce962c9-bc3a-4d3c-b731-5319594e20c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ce962c9-bc3a-4d3c-b731-5319594e20c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# OneHotEncoding on Train set (fit & transform)\n",
        "# OneHotEncoding is to be done on Categorical variables.\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "Xcat = pd.DataFrame(ohe.fit_transform(X[categoricalFeatures]),columns=ohe.get_feature_names(),index=X.index)\n",
        "Xtrain = pd.concat([X,Xcat],axis=1) \n",
        "Xtrain.drop(labels=categoricalFeatures,axis=1,inplace=True)\n",
        "Xtrain = Xtrain.drop(['Open Date'], axis = 1)\n",
        "Xtrain.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OneHotEncoding on Test Data set (fit & transform)\n",
        "# OneHotEncoding is to be done on Categorical variables.\n",
        "\n",
        "Xcat = pd.DataFrame(ohe.transform(X_Test[categoricalFeatures]),columns=ohe.get_feature_names(),index=X_Test.index)\n",
        "XTest = pd.concat([X_Test,Xcat],axis=1) \n",
        "XTest.drop(labels=categoricalFeatures,axis=1,inplace=True)\n",
        "XTest = XTest.drop(['Open Date'], axis = 1)\n",
        "XTest.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "n22Fi2k_lsUX",
        "outputId": "94e9b644-a8d0-4715-a5b2-56b8c5f25384"
      },
      "id": "n22Fi2k_lsUX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       P1   P2   P3   P4  P5  P6  P7  P8  P9  P10  ...  x5_2005  x5_2006  \\\n",
              "84505   3  4.0  4.0  3.0   1   3   5   4   5    4  ...      0.0      0.0   \n",
              "92175   2  3.0  4.0  4.0   2   2   2   4   4    5  ...      0.0      0.0   \n",
              "35489   3  5.0  3.0  4.0   4   3   5   5   5    5  ...      0.0      0.0   \n",
              "97757   3  7.5  6.0  3.0   1   4   5   5   5    5  ...      0.0      0.0   \n",
              "31317   6  4.0  4.0  4.0   1   6  10   4   5    5  ...      0.0      0.0   \n",
              "\n",
              "       x5_2007  x5_2008  x5_2009  x5_2010  x5_2011  x5_2012  x5_2013  x5_2014  \n",
              "84505      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0  \n",
              "92175      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0  \n",
              "35489      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
              "97757      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0  \n",
              "31317      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0  \n",
              "\n",
              "[5 rows x 135 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-712dd64b-3171-4d63-ac4b-a59e6384c31d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P1</th>\n",
              "      <th>P2</th>\n",
              "      <th>P3</th>\n",
              "      <th>P4</th>\n",
              "      <th>P5</th>\n",
              "      <th>P6</th>\n",
              "      <th>P7</th>\n",
              "      <th>P8</th>\n",
              "      <th>P9</th>\n",
              "      <th>P10</th>\n",
              "      <th>...</th>\n",
              "      <th>x5_2005</th>\n",
              "      <th>x5_2006</th>\n",
              "      <th>x5_2007</th>\n",
              "      <th>x5_2008</th>\n",
              "      <th>x5_2009</th>\n",
              "      <th>x5_2010</th>\n",
              "      <th>x5_2011</th>\n",
              "      <th>x5_2012</th>\n",
              "      <th>x5_2013</th>\n",
              "      <th>x5_2014</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84505</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92175</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35489</th>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97757</th>\n",
              "      <td>3</td>\n",
              "      <td>7.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31317</th>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 135 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-712dd64b-3171-4d63-ac4b-a59e6384c31d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-712dd64b-3171-4d63-ac4b-a59e6384c31d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-712dd64b-3171-4d63-ac4b-a59e6384c31d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdf7f11",
      "metadata": {
        "id": "abdf7f11",
        "outputId": "9c3a3cf0-2661-4748-ce67-7d61e251f3ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3653259.93377381 4009436.08396825 4228506.06161111 ... 4311483.49266667\n",
            " 4532886.51016667 4602807.265     ]\n"
          ]
        }
      ],
      "source": [
        "# Model #1: Random Forest Regressor\n",
        "\n",
        "regr1 = RandomForestRegressor()\n",
        "regr1 = RandomForestRegressor(n_estimators= 100, max_depth=25,max_leaf_nodes = 75)\n",
        "regr1.fit(Xtrain, Y)\n",
        "\n",
        "#Predicting the Revenue on the Test Data Set\n",
        "rfr_predict_Test=regr1.predict(XTest)\n",
        "print(rfr_predict_Test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning for Random Forest Regressor\n",
        "\n",
        "#Random Search\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"RandomizedSearchCV - Random Forest Regressor\")\n",
        "rand_parameters={'min_samples_leaf' : range(10,200,20),'max_depth': \n",
        "            range(1,50,6), 'max_leaf_nodes': \n",
        "            range(1,75,8)}\n",
        "\n",
        "rf_random = RandomizedSearchCV(regr1,rand_parameters,n_iter=25,cv=5)\n",
        "rf_random.fit(Xtrain, Y)\n",
        "rand_parm=rf_random.best_params_\n",
        "print(rand_parm)\n",
        "\n",
        "\n",
        "#Grid Search\n",
        "\n",
        "print(\"GridSearchCV - Random Forest Regressor\")\n",
        "rf_grid = GridSearchCV(regr1,rand_parameters)\n",
        "rf_grid.fit(Xtrain, Y)\n",
        "grid_parm1=rf_grid.best_params_\n",
        "print(grid_parm1)\n",
        "\n",
        "##Using the parameters obtained from HyperParameterTuning in the RandomForestRegressor\n",
        "\n",
        "rfRand = RandomForestRegressor(**rand_parm)\n",
        "rfGrid = RandomForestRegressor(**grid_parm1)\n",
        "\n",
        "rfRand.fit(Xtrain,Y)\n",
        "rfRand_predict = rfRand.predict(XTest)\n",
        "\n",
        "rfGrid.fit(Xtrain,Y)\n",
        "rfGrid_predict = rfGrid.predict(XTest)\n",
        "\n",
        "#Writing the Predictions to CSV file\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "\n",
        "rfr_random_prediction = pd.DataFrame({\"Id\":testData_id, \"Prediction\":rfRand_predict})  \n",
        "rfr_random_prediction.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/Random_Search_Submission.csv',index=None)\n",
        "\n",
        "\n",
        "rfr_grid_prediction = pd.DataFrame({\"Id\":testData_id, \"Prediction\":rfGrid_predict})  \n",
        "rfr_grid_prediction.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/Grid_Search_Submission.csv',index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6hSQSpQBT9c",
        "outputId": "2e4d3866-e5f1-46c8-84b0-7a4597c45b4a"
      },
      "id": "_6hSQSpQBT9c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV - Random Forest Regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 125.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 316, in fit\n",
            "    max_leaf_nodes\n",
            "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.01630568         nan  0.01825584         nan -0.01768661 -0.02052588\n",
            " -0.01901403 -0.01726377 -0.01713086 -0.01770821 -0.01692731 -0.01863261\n",
            "  0.0717628   0.07827065 -0.01626235 -0.02020688 -0.0187465  -0.01751729\n",
            "  0.07882667 -0.0172268  -0.01736082 -0.01780088 -0.01682908  0.05225124\n",
            " -0.01633048]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_samples_leaf': 10, 'max_leaf_nodes': 33, 'max_depth': 25}\n",
            "GridSearchCV - Random Forest Regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "450 fits failed out of a total of 4500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "450 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 316, in fit\n",
            "    max_leaf_nodes\n",
            "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan  0.03672686  0.00557488\n",
            " -0.01733314 -0.01779807 -0.0172022  -0.01922995 -0.01680224 -0.0157429\n",
            " -0.01852411 -0.01741282  0.0304818   0.00051378 -0.0154545  -0.01685811\n",
            " -0.01841165 -0.01667674 -0.0152763  -0.01832138 -0.01623497 -0.01579513\n",
            "  0.02341315  0.01711737 -0.01684759 -0.01858092 -0.01833975 -0.01714857\n",
            " -0.01654235 -0.01843527 -0.01841756 -0.01541259  0.02879583 -0.00068976\n",
            " -0.01784206 -0.01497367 -0.01854345 -0.01799319 -0.01634947 -0.01581061\n",
            " -0.01667004 -0.01751776  0.02496806  0.00619942 -0.01780078 -0.0176014\n",
            " -0.01686011 -0.0169367  -0.01535293 -0.01765837 -0.01554374 -0.01715357\n",
            "  0.01951166  0.00770781 -0.01624373 -0.01743505 -0.0164859  -0.01930894\n",
            " -0.01711018 -0.01837888 -0.01816204 -0.01553537  0.03436345  0.00731353\n",
            " -0.01833398 -0.01706426 -0.01739935 -0.01595543 -0.01781521 -0.01794144\n",
            " -0.01735589 -0.01523527  0.03430243 -0.00402922 -0.01796158 -0.01645667\n",
            " -0.01745723 -0.01746449 -0.01729896 -0.01647626 -0.01740217 -0.0169625\n",
            "  0.02899052  0.01155921 -0.01708179 -0.01838465 -0.01616277 -0.01911111\n",
            " -0.01652397 -0.01666032 -0.01760825 -0.01810431         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan  0.05904068  0.01187674 -0.01668437 -0.01698253\n",
            " -0.01559383 -0.01651249 -0.01840382 -0.01817584 -0.01786204 -0.01830504\n",
            "  0.07863477  0.01505829 -0.01692932 -0.01847056 -0.0181959  -0.01680887\n",
            " -0.01757581 -0.01733976 -0.0188533  -0.01555779  0.06971374  0.00540674\n",
            " -0.01681142 -0.01708348 -0.01708686 -0.01788305 -0.01811672 -0.01781116\n",
            " -0.01816187 -0.01702787  0.0720792   0.00156654 -0.01497203 -0.01893085\n",
            " -0.01741305 -0.01724698 -0.01613295 -0.0165891  -0.01518011 -0.01630152\n",
            "  0.08585581  0.00707471 -0.01754511 -0.01746629 -0.01838678 -0.01888222\n",
            " -0.01882448 -0.01754622 -0.01720411 -0.01836454  0.07428819  0.01424963\n",
            " -0.01979939 -0.01633394 -0.01762542 -0.01669221 -0.01679003 -0.01620998\n",
            " -0.01626679 -0.01630717  0.08472715 -0.00557937 -0.01584323 -0.01569966\n",
            " -0.01568003 -0.01837351 -0.0185718  -0.01788367 -0.01738026 -0.01666711\n",
            "  0.0676591   0.00486536 -0.0156824  -0.01790166 -0.01880965 -0.01706328\n",
            " -0.01521874 -0.01864944 -0.01714988 -0.01896323  0.06347491  0.0033148\n",
            " -0.01825801 -0.01846102 -0.0159156  -0.01647975 -0.0180554  -0.01694496\n",
            " -0.01670875 -0.01833825         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.05531295  0.01629495 -0.01804503 -0.01791862 -0.01711823 -0.01837392\n",
            " -0.01754842 -0.01681442 -0.01741546 -0.01509045  0.06354126 -0.00600085\n",
            " -0.0165917  -0.01745939 -0.01747971 -0.01719227 -0.01763779 -0.01797404\n",
            " -0.01935829 -0.0167074   0.08342713  0.0150896  -0.01677458 -0.0154142\n",
            " -0.01784075 -0.01696247 -0.01736804 -0.01700509 -0.01630472 -0.01698574\n",
            "  0.07574585  0.01009704 -0.01594873 -0.01680737 -0.01537767 -0.01764859\n",
            " -0.01626701 -0.0170353  -0.01742408 -0.01833251  0.08985324  0.0054743\n",
            " -0.0166803  -0.01734614 -0.01465351 -0.01929762 -0.01813197 -0.01684282\n",
            " -0.01623525 -0.01658336  0.06143554  0.00418664 -0.01631545 -0.01912424\n",
            " -0.01632448 -0.01664009 -0.0178015  -0.01913311 -0.01780346 -0.01575346\n",
            "  0.08378656  0.00777559 -0.01720569 -0.01580968 -0.01713015 -0.01618093\n",
            " -0.01674035 -0.01855556 -0.01717071 -0.01847484  0.08907004  0.00619575\n",
            " -0.01668456 -0.01604894 -0.0157956  -0.0172136  -0.01726214 -0.01594626\n",
            " -0.01986346 -0.01705888  0.06527755  0.00348681 -0.01813608 -0.01506441\n",
            " -0.01698377 -0.01915142 -0.01727325 -0.01657767 -0.01807753 -0.01757124\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan  0.06534918  0.01357511\n",
            " -0.01720019 -0.01786537 -0.01811473 -0.01787479 -0.01865802 -0.01877069\n",
            " -0.01640643 -0.01797373  0.07534087  0.00182327 -0.01739234 -0.01470399\n",
            " -0.01697983 -0.01884593 -0.01808964 -0.01653454 -0.01663056 -0.01770185\n",
            "  0.0734539   0.00489108 -0.01726515 -0.01682114 -0.01795383 -0.01676546\n",
            " -0.01884942 -0.01922233 -0.01879347 -0.01728501  0.08741034  0.00840174\n",
            " -0.01717278 -0.01774679 -0.01689997 -0.01757778 -0.01623299 -0.01813251\n",
            " -0.01742432 -0.01508129  0.05402042  0.00757679 -0.01853302 -0.01741202\n",
            " -0.01696755 -0.01560637 -0.01697081 -0.01713331 -0.01688856 -0.01738256\n",
            "  0.07171503  0.00389347 -0.01757712 -0.01694464 -0.01709105 -0.01625759\n",
            " -0.01815111 -0.01722224 -0.01679311 -0.01673743  0.06419521  0.0112564\n",
            " -0.01612935 -0.01743845 -0.01799412 -0.01649203 -0.01635455 -0.01673895\n",
            " -0.01862111 -0.0181504   0.06388108  0.00665823 -0.01536682 -0.01768027\n",
            " -0.01801147 -0.01742341 -0.01730882 -0.01701942 -0.01882778 -0.01784436\n",
            "  0.07218965  0.00424407 -0.01542883 -0.01788486 -0.01609918 -0.01857227\n",
            " -0.01553682 -0.01906068 -0.01545356 -0.01811086         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan  0.06795731  0.00579247 -0.01759866 -0.01722748\n",
            " -0.01718104 -0.01587791 -0.01555601 -0.01871124 -0.01718081 -0.018406\n",
            "  0.07076696  0.01659364 -0.01738808 -0.01744279 -0.01591358 -0.01861988\n",
            " -0.01643307 -0.01743994 -0.01896273 -0.0175076   0.05688963  0.0068315\n",
            " -0.01880017 -0.0167926  -0.01597782 -0.01514124 -0.01796801 -0.01675182\n",
            " -0.01772692 -0.0165476   0.09213878  0.01474712 -0.01766358 -0.01764667\n",
            " -0.0191427  -0.01698804 -0.01732607 -0.01633064 -0.01808214 -0.01786174\n",
            "  0.07024943  0.00625296 -0.01839576 -0.01665408 -0.01716431 -0.01736362\n",
            " -0.01724662 -0.01736055 -0.01656625 -0.017864    0.09878277 -0.00152044\n",
            " -0.01891074 -0.01848227 -0.01718088 -0.01554149 -0.01780989 -0.01826446\n",
            " -0.02009378 -0.01835861  0.04975156 -0.00337643 -0.01789311 -0.0181257\n",
            " -0.01559722 -0.01895519 -0.01488708 -0.01697869 -0.01617157 -0.01668371\n",
            "  0.07943899 -0.00354768 -0.01738152 -0.01842616 -0.01760508 -0.01645552\n",
            " -0.01797067 -0.01856794 -0.01791621 -0.01725399  0.08655101  0.01155725\n",
            " -0.01612328 -0.01664029 -0.01872861 -0.01641444 -0.01710083 -0.01792008\n",
            " -0.01681455 -0.0165142          nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.08041554  0.01753972 -0.01865955 -0.01808004 -0.01570149 -0.01676913\n",
            " -0.01893158 -0.01546614 -0.01667452 -0.01740438  0.08471542  0.01712384\n",
            " -0.01675272 -0.01809651 -0.01745141 -0.01905486 -0.01819603 -0.01755943\n",
            " -0.01588932 -0.01692652  0.06890959  0.02390805 -0.01746669 -0.01675693\n",
            " -0.01782158 -0.01586098 -0.01809647 -0.01788514 -0.0160654  -0.01583476\n",
            "  0.0796459   0.00010291 -0.01676765 -0.01723247 -0.01506521 -0.01744601\n",
            " -0.01626442 -0.01810147 -0.0156638  -0.01859485  0.05684906  0.00272035\n",
            " -0.01603178 -0.01879224 -0.01668823 -0.01842868 -0.01698172 -0.01780209\n",
            " -0.01660854 -0.01647232  0.07283595 -0.00050943 -0.01687342 -0.01656038\n",
            " -0.01769623 -0.01714527 -0.01519937 -0.01783316 -0.016145   -0.01900711\n",
            "  0.07272678 -0.00085704 -0.01532239 -0.01603226 -0.0166688  -0.01741258\n",
            " -0.01760609 -0.01619204 -0.01851453 -0.01978751  0.07295937 -0.00121354\n",
            " -0.01711624 -0.01685035 -0.01771247 -0.01889167 -0.01989577 -0.01827479\n",
            " -0.01826084 -0.01761958  0.06406175  0.00471888 -0.01666029 -0.0166848\n",
            " -0.01665844 -0.01725034 -0.01711981 -0.01822968 -0.01681043 -0.01967271\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan  0.07135866  0.00271906\n",
            " -0.01714551 -0.01655401 -0.01646506 -0.01608968 -0.01730625 -0.01779155\n",
            " -0.01651003 -0.01770949  0.07372334  0.00790928 -0.01597489 -0.01677917\n",
            " -0.01656794 -0.01649325 -0.01832378 -0.0165103  -0.01596022 -0.01594128\n",
            "  0.06516235  0.00795477 -0.01768162 -0.01746028 -0.01713611 -0.01880159\n",
            " -0.01694491 -0.0180491  -0.01560748 -0.01709231  0.077656    0.00694971\n",
            " -0.01804625 -0.01526551 -0.018608   -0.0188281  -0.0168574  -0.01642725\n",
            " -0.01936655 -0.01926661  0.06381533  0.01227935 -0.01656307 -0.01641603\n",
            " -0.01805131 -0.01932971 -0.01841044 -0.01998057 -0.0169673  -0.01660242\n",
            "  0.08065908  0.00725482 -0.01655222 -0.01846042 -0.01723366 -0.01787324\n",
            " -0.01881278 -0.01781727 -0.01967989 -0.01743362  0.07716424  0.00650793\n",
            " -0.01459239 -0.01593806 -0.01660312 -0.01704412 -0.01562406 -0.01549236\n",
            " -0.01901345 -0.01762761  0.07629142 -0.00037705 -0.01733414 -0.01619145\n",
            " -0.02100084 -0.01775828 -0.01917404 -0.01677108 -0.01759679 -0.01579321\n",
            "  0.0529193   0.01380933 -0.01523143 -0.0166539  -0.01780691 -0.01694404\n",
            " -0.01733354 -0.01764431 -0.01702618 -0.01965184         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan  0.0671713   0.00831942 -0.01789024 -0.01572553\n",
            " -0.01706151 -0.01913038 -0.01554636 -0.01727539 -0.01738186 -0.01889054\n",
            "  0.06660442  0.00066507 -0.01765028 -0.01530415 -0.01778582 -0.01890943\n",
            " -0.017127   -0.01813722 -0.01761269 -0.01652242  0.07314937 -0.00589838\n",
            " -0.0165788  -0.01813062 -0.01701074 -0.01719748 -0.01721919 -0.01775675\n",
            " -0.01696826 -0.01715155  0.06230581  0.00461814 -0.01650889 -0.01709886\n",
            " -0.01790813 -0.01674479 -0.0158328  -0.01963084 -0.01866105 -0.01692803\n",
            "  0.08424188  0.00847238 -0.01726105 -0.0171821  -0.01519353 -0.01723719\n",
            " -0.01606857 -0.01729906 -0.01735804 -0.0185875   0.06359287  0.01238522\n",
            " -0.01834748 -0.01745603 -0.01683458 -0.01824946 -0.01745561 -0.01720407\n",
            " -0.017751   -0.01894644  0.07804441  0.00042456 -0.01799676 -0.01707804\n",
            " -0.01688189 -0.01488803 -0.01521278 -0.01575173 -0.01952173 -0.01650048\n",
            "  0.08242945  0.00564138 -0.01646015 -0.01798513 -0.01790734 -0.01740136\n",
            " -0.01780059 -0.01700034 -0.01924869 -0.01620277  0.08617439  0.00835341\n",
            " -0.01829684 -0.0183475  -0.0167186  -0.01830226 -0.01743966 -0.01860568\n",
            " -0.01718024 -0.01661671         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.07658746  0.00801101 -0.01754584 -0.01860306 -0.01909666 -0.01731608\n",
            " -0.01637239 -0.01656138 -0.01758988 -0.01711569  0.06975472  0.00216466\n",
            " -0.01718897 -0.01716757 -0.01644498 -0.01733695 -0.01621556 -0.01857954\n",
            " -0.01626418 -0.01864842  0.04831541  0.00577276 -0.01710514 -0.01690286\n",
            " -0.01862316 -0.01758239 -0.01643208 -0.01781868 -0.01742222 -0.01719667\n",
            "  0.06851391  0.00982015 -0.01832668 -0.0177586  -0.01629869 -0.01669512\n",
            " -0.01538192 -0.01635476 -0.01726713 -0.01881965  0.07564057  0.01152102\n",
            " -0.01816807 -0.01773492 -0.01759871 -0.0163892  -0.01696801 -0.01668405\n",
            " -0.01590062 -0.01833355  0.07145011  0.01347762 -0.01744205 -0.01791627\n",
            " -0.01576852 -0.01883771 -0.018482   -0.01703714 -0.01602153 -0.01549283\n",
            "  0.06083195 -0.00155339 -0.01685733 -0.01856223 -0.01706875 -0.01798175\n",
            " -0.01765619 -0.0164381  -0.01869892 -0.01700618  0.0714582   0.00035177\n",
            " -0.01768716 -0.01827194 -0.01628265 -0.01688373 -0.01689742 -0.01776298\n",
            " -0.01673869 -0.01706628  0.079892    0.0074662  -0.01741816 -0.01625552\n",
            " -0.01658306 -0.01658363 -0.01770066 -0.01866401 -0.019542   -0.01641618]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 25, 'max_leaf_nodes': 49, 'min_samples_leaf': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2 : SVR Regressor\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "regr2 =SVR(gamma=0.1,C=100.0, epsilon=0.1)\n",
        "regr2.fit(Xtrain, Y)\n",
        "\n",
        "#Predicting the Revenue on the Test Data Set\n",
        "regr2_predict_Test=regr2.predict(XTest)\n",
        "print(regr2.predict(XTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekCx80uIJU4i",
        "outputId": "3d4da67d-c139-4493-ddeb-332ee6345de4"
      },
      "id": "ekCx80uIJU4i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3939770.11882467 3939750.56344247 3939796.10465338 ... 3939773.78836791\n",
            " 3939772.90944653 3939772.90846693]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter tuning for SVR model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],'kernel': ['rbf', 'linear', 'poly']} \n",
        "  \n",
        "regr2_grid = GridSearchCV(regr2, param_grid, refit = True, verbose = 3)\n",
        "regr2_random= RandomizedSearchCV(regr2,param_grid,n_iter=15)  \n",
        "\n",
        "# Fitting the model for Grid Search\n",
        "regr2_grid.fit(Xtrain, Y)\n",
        "grid_parm=regr2_grid.best_params_\n",
        "print(grid_parm)\n",
        "\n",
        "#Fitting the model for Random Search\n",
        "regr2_random.fit(Xtrain,Y)\n",
        "random_parm=regr2_random.best_params_\n",
        "print(random_parm)\n",
        "\n",
        "#Using the best parameters obtained from HyperParameterTuning in the SVRClassifier \n",
        "\n",
        "SVRGrid = SVR(**grid_parm)\n",
        "SVRGrid.fit(Xtrain,Y)\n",
        "SVR_gridpredict = SVRGrid.predict(XTest)\n",
        "\n",
        "SVRRand=SVR(**random_parm)\n",
        "SVRRand.fit(Xtrain,Y)\n",
        "SVR_randpredict = SVRRand.predict(XTest)\n",
        "\n",
        "#Writing the Predictions to CSV file\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "\n",
        "SVR_prediction_grid = pd.DataFrame({\"Id\":testData_id, \"Prediction\":SVR_gridpredict})  \n",
        "SVR_prediction_grid.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/SVR_Grid.csv',index=None)\n",
        "\n",
        "SVR_prediction_random = pd.DataFrame({\"Id\":testData_id, \"Prediction\":SVR_randpredict})  \n",
        "SVR_prediction_random.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/SVR_Random.csv',index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BT38K_PJV5B",
        "outputId": "8cdfa11c-a284-4651-debf-cddbc63db7d3"
      },
      "id": "2BT38K_PJV5B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END .......C=0.1, gamma=1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .......C=0.1, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .......C=0.1, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .......C=0.1, gamma=1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .......C=0.1, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .........C=1, gamma=1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .........C=1, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .........C=1, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .........C=1, gamma=1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .........C=1, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .......C=1, gamma=0.1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, gamma=0.1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, gamma=0.1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ......C=1, gamma=0.01, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ......C=1, gamma=0.01, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=0.01, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=0.001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .....C=1, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .....C=1, gamma=0.001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .....C=1, gamma=0.001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .....C=1, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ....C=1, gamma=0.0001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ....C=1, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ....C=1, gamma=0.0001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ....C=1, gamma=0.0001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ....C=1, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ........C=10, gamma=1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ........C=10, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ........C=10, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ........C=10, gamma=1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ........C=10, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=0.1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, gamma=0.1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, gamma=0.1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=0.01, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=0.01, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=0.01, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=0.001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=0.001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=0.001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ....C=10, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ...C=10, gamma=0.0001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ...C=10, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ...C=10, gamma=0.0001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ...C=10, gamma=0.0001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ...C=10, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .......C=100, gamma=1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .......C=100, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .......C=100, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .......C=100, gamma=1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .......C=100, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END .....C=100, gamma=0.1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .....C=100, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .....C=100, gamma=0.1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .....C=100, gamma=0.1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .....C=100, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ....C=100, gamma=0.01, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ....C=100, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ....C=100, gamma=0.01, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ....C=100, gamma=0.01, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ....C=100, gamma=0.01, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ...C=100, gamma=0.001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ...C=100, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ...C=100, gamma=0.001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ...C=100, gamma=0.001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ...C=100, gamma=0.001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ..C=100, gamma=0.0001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ..C=100, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ..C=100, gamma=0.0001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ..C=100, gamma=0.0001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ..C=100, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ......C=1000, gamma=1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ......C=1000, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ......C=1000, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END ......C=1000, gamma=1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ......C=1000, gamma=1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ....C=1000, gamma=0.1, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END ....C=1000, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END ....C=1000, gamma=0.1, kernel=rbf;, score=-0.000 total time=   0.0s\n",
            "[CV 4/5] END ....C=1000, gamma=0.1, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ....C=1000, gamma=0.1, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 1/5] END ...C=1000, gamma=0.01, kernel=rbf;, score=-0.095 total time=   0.0s\n",
            "[CV 2/5] END ...C=1000, gamma=0.01, kernel=rbf;, score=-0.048 total time=   0.0s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END ...C=1000, gamma=0.01, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ...C=1000, gamma=0.01, kernel=rbf;, score=-0.051 total time=   0.0s\n",
            "[CV 1/5] END ..C=1000, gamma=0.001, kernel=rbf;, score=-0.095 total time=   0.0s\n",
            "[CV 2/5] END ..C=1000, gamma=0.001, kernel=rbf;, score=-0.048 total time=   0.0s\n",
            "[CV 3/5] END ..C=1000, gamma=0.001, kernel=rbf;, score=-0.000 total time=   0.0s\n",
            "[CV 4/5] END ..C=1000, gamma=0.001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END ..C=1000, gamma=0.001, kernel=rbf;, score=-0.050 total time=   0.0s\n",
            "[CV 1/5] END .C=1000, gamma=0.0001, kernel=rbf;, score=-0.094 total time=   0.0s\n",
            "[CV 2/5] END .C=1000, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "[CV 3/5] END .C=1000, gamma=0.0001, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 4/5] END .C=1000, gamma=0.0001, kernel=rbf;, score=-0.082 total time=   0.0s\n",
            "[CV 5/5] END .C=1000, gamma=0.0001, kernel=rbf;, score=-0.049 total time=   0.0s\n",
            "{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "{'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e078e88",
      "metadata": {
        "id": "1e078e88",
        "outputId": "92506b83-d063-4d1f-e49e-c9cad35bfdf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4067566. 4067566. 2025297. ... 3727364. 4350573. 3752885.]\n",
            "The best parameters based on RandomizedSearchCV is {'splitter': 'best', 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 1024, 'criterion': 'squared_error'}\n",
            "\n",
            "The cross-validated training r-sq is: 0.28\n",
            "The best parameters based on GridSearchCV is {'criterion': 'squared_error', 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 3, 'splitter': 'best'}\n"
          ]
        }
      ],
      "source": [
        "# Model 3: Decision Tree Regressor\n",
        "regr3 = DecisionTreeRegressor(random_state = 42)\n",
        "regr3.fit(Xtrain, Y)\n",
        "\n",
        "#Predicting the Revenue on the Test Data Set\n",
        "dt_predict_Test=regr3.predict(XTest)\n",
        "print(dt_predict_Test)\n",
        "\n",
        "# Hyper Parameter Tuning for Decision Tree Regressor\n",
        "parameters = {\n",
        "    'criterion': (['squared_error']),\n",
        "    'splitter': ('best', 'random'),\n",
        "    'max_depth': (8,16,32,64,128,256,512,1024,2048),\n",
        "    'max_features': ('sqrt', 'log2'),\n",
        "    'min_samples_leaf': ([1,2,3,4])\n",
        "}\n",
        "\n",
        "#Fitting the model on Random Search\n",
        "test1 = RandomizedSearchCV(regr3, parameters, cv=5)\n",
        "test1.fit(Xtrain, Y)\n",
        "\n",
        "rand_params = test1.best_params_\n",
        "print(\"The best parameters based on RandomizedSearchCV is\", rand_params)\n",
        "print()\n",
        "\n",
        "#Fitting the model on Grid Search\n",
        "test2 = GridSearchCV(regr3, parameters, cv=5)\n",
        "test2.fit(Xtrain, Y)\n",
        "print('The cross-validated training r-sq is: %.2f'% test2.score(Xtrain, Y))\n",
        "\n",
        "grid_params = test2.best_params_\n",
        "print(\"The best parameters based on GridSearchCV is\", grid_params)\n",
        "\n",
        "## Using the parameters obtained from HyperParameterTuning in the RandomForestRegressor\n",
        "dtRand = DecisionTreeRegressor(**rand_params)\n",
        "dtGrid = DecisionTreeRegressor(**grid_params)\n",
        "\n",
        "dtRand.fit(Xtrain, Y)\n",
        "dtRand_predict = dtRand.predict(XTest)\n",
        "dtGrid.fit(Xtrain, Y)\n",
        "dtGrid_predict = dtGrid.predict(XTest)\n",
        "\n",
        "#Writing the Predictions to CSV file\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "\n",
        "dtr_prediction_random = pd.DataFrame({\"Id\":testData_id, \"Prediction\": dtRand_predict})\n",
        "dtr_prediction_grid = pd.DataFrame({\"Id\":testData_id, \"Prediction\": dtGrid_predict})\n",
        "\n",
        "dtr_prediction_random.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/dt_submission_random.csv',index=None)\n",
        "dtr_prediction_grid.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/dt_submission_grid.csv',index=None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d803a3a3",
      "metadata": {
        "id": "d803a3a3",
        "outputId": "c11f0ea9-02ff-455f-9c42-9f4d8e5458ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40176.64549683 37580.1988955  45301.23965446 ... 73521.04966689\n",
            " 91926.20446729 53505.5874903 ]\n",
            "MLP Randomized Search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 18 is smaller than n_iter=25. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-4.45656554e-02 -6.38852258e-02 -4.45656554e-02 -7.95264953e-02\n",
            " -4.45656554e-02 -1.65158533e-02 -1.04712917e+00 -4.98577778e+05\n",
            " -1.04712917e+00 -2.81060101e+05 -1.04712917e+00 -2.86345436e+03\n",
            " -3.57159973e+01             nan -3.57159973e+01             nan\n",
            " -3.57159973e+01             nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'solver': 'sgd', 'learning_rate': 'invscaling', 'activation': 'logistic'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-4.45656554e-02 -6.38852258e-02 -4.45656554e-02 -7.95264953e-02\n",
            " -4.45656554e-02 -1.65158533e-02 -1.04712917e+00 -4.98577778e+05\n",
            " -1.04712917e+00 -2.81060101e+05 -1.04712917e+00 -2.86345436e+03\n",
            " -3.57159973e+01             nan -3.57159973e+01             nan\n",
            " -3.57159973e+01             nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        " # Model 4: MLP Regressor \n",
        "regr4 = MLPRegressor()\n",
        "regr4 = MLPRegressor(random_state=1, max_iter=2000)\n",
        "regr4.fit(Xtrain, Y)\n",
        "\n",
        "#Predicting the test data\n",
        "mlpr_predict_Test = regr4.predict(XTest)\n",
        "print(mlpr_predict_Test)\n",
        "\n",
        "print(\"MLP Randomized Search\")\n",
        "\n",
        "#hyperparameter tuning\n",
        "rand_parameters = {'learning_rate' : ['adaptive', 'constant', 'invscaling'], 'activation' : ['logistic', 'relu', 'identity'], 'solver': ['lbfgs', 'sgd']}\n",
        "\n",
        "#Fitting the model on Random Search\n",
        "mlpr_random  = RandomizedSearchCV(regr4, rand_parameters, n_iter=25, cv=5)\n",
        "mlpr_random.fit(Xtrain,Y)\n",
        "rand_parm_mlp = mlpr_random.best_params_\n",
        "print(rand_parm_mlp)\n",
        "\n",
        "#Fitting the model on Grid Search\n",
        "mlpr_grid = GridSearchCV(regr4, rand_parameters, cv=5)\n",
        "mlpr_grid.fit(Xtrain,Y)\n",
        "grid_parm_mlp = mlpr_grid.best_params_\n",
        "print(grid_parm_mlp)\n",
        "\n",
        "mlprRand = MLPRegressor(**rand_parm_mlp)\n",
        "mlprGrid = MLPRegressor(**grid_parm_mlp)\n",
        "\n",
        "#New Regressor with the best parameters\n",
        "mlprRand.fit(Xtrain,Y)\n",
        "mlprRand_predict = mlprRand.predict(XTest)\n",
        "\n",
        "mlprGrid.fit(Xtrain,Y)\n",
        "mlprGrid_predict = mlprGrid.predict(XTest)\n",
        "\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "mlpr_prediction_random = pd.DataFrame({\"Id\":testData_id, \"Prediction\":mlprRand_predict})\n",
        "mlpr_prediction_grid = pd.DataFrame({\"Id\":testData_id, \"Prediction\":mlprGrid_predict})\n",
        "\n",
        "mlpr_prediction_random.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/MLP_Random.csv',index=None)\n",
        "mlpr_prediction_grid.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/MLP_Grid.csv',index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5f8d49",
      "metadata": {
        "id": "ed5f8d49",
        "outputId": "f43f8380-a002-4410-fd55-ea49ad53dd5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3781455.16013271 6877238.18133739 4393586.57760239 ... 8440802.87630603\n",
            " 4629247.66628354 3077325.76752639]\n",
            "[ 1.20241103e+11  1.37047690e+11  5.14504185e+10 ... -1.78687487e+11\n",
            " -3.43138992e+11  5.32733948e+10]\n"
          ]
        }
      ],
      "source": [
        "#Model 5: SGD Regressor\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Always scale the input. The most convenient way is to use a pipeline.\n",
        "reg5 = make_pipeline(StandardScaler(), SGDRegressor(max_iter=2000, tol=1e-3))\n",
        "reg5.fit(Xtrain, Y)\n",
        "sgd_test_prediction = reg5.predict(XTest)\n",
        "print(reg5.predict(XTest))\n",
        "\n",
        "reg5_SGD = SGDRegressor()\n",
        "reg5_SGD.fit(Xtrain, Y)\n",
        "sgd_test_prediction_normal = reg5_SGD.predict(XTest)\n",
        "print(reg5_SGD.predict(XTest))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning done for SGD Regressor\n",
        "param_grid={'loss' : ['squared_error', 'huber', 'epsilon_insensitive','squared_epsilon_insensitive'], \n",
        "            'penalty' : ['l1', 'l2', 'elasticnet'], \n",
        "            'alpha' : [0.01, 0.1, 1, 10]}\n",
        "\n",
        "#Grid Search\n",
        "sgd_grid = GridSearchCV(reg5_SGD, param_grid, refit = True, verbose = 3)\n",
        "\n",
        "#Random Search\n",
        "sgd_random = RandomizedSearchCV(reg5_SGD, param_grid,n_iter=10,cv=5)\n",
        "\n",
        "# Fitting the model for grid search\n",
        "sgd_grid.fit(Xtrain, Y)\n",
        "grid_parm_sgd=sgd_grid.best_params_\n",
        "print(grid_parm_sgd)\n",
        "\n",
        "#Fitting the model for random search\n",
        "sgd_random.fit(Xtrain, Y)\n",
        "random_parm_sgd=sgd_random.best_params_\n",
        "print(random_parm_sgd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OgT3y03ZsMH",
        "outputId": "ee170abf-ce2c-45f0-9a87-ed2a61dfc4d6"
      },
      "id": "5OgT3y03ZsMH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV 1/5] END alpha=0.01, loss=squared_error, penalty=l1;, score=-11057858511.030 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_error, penalty=l1;, score=-6584117342.652 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_error, penalty=l1;, score=-14854597672.426 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_error, penalty=l1;, score=-31185825233.469 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_error, penalty=l1;, score=-5860129622.298 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.01, loss=squared_error, penalty=l2;, score=-16800463122.251 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_error, penalty=l2;, score=-2806227293.935 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_error, penalty=l2;, score=-30052934577.047 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_error, penalty=l2;, score=-63191925294.810 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_error, penalty=l2;, score=-981093836530.783 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.01, loss=squared_error, penalty=elasticnet;, score=-4956959904.721 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_error, penalty=elasticnet;, score=-3662134093.454 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_error, penalty=elasticnet;, score=-2300736860.689 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_error, penalty=elasticnet;, score=-21061031999.057 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_error, penalty=elasticnet;, score=-16222376237.969 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.01, loss=huber, penalty=l1;, score=-2.061 total time=   0.2s\n",
            "[CV 2/5] END alpha=0.01, loss=huber, penalty=l1;, score=-5.925 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.01, loss=huber, penalty=l1;, score=-2.211 total time=   0.2s\n",
            "[CV 4/5] END alpha=0.01, loss=huber, penalty=l1;, score=-3.263 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.01, loss=huber, penalty=l1;, score=-5.015 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.01, loss=huber, penalty=l2;, score=-2.062 total time=   0.1s\n",
            "[CV 2/5] END alpha=0.01, loss=huber, penalty=l2;, score=-5.927 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.01, loss=huber, penalty=l2;, score=-2.212 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.01, loss=huber, penalty=l2;, score=-3.264 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.01, loss=huber, penalty=l2;, score=-5.017 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.01, loss=huber, penalty=elasticnet;, score=-2.062 total time=   0.1s\n",
            "[CV 2/5] END alpha=0.01, loss=huber, penalty=elasticnet;, score=-5.927 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.01, loss=huber, penalty=elasticnet;, score=-2.212 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.01, loss=huber, penalty=elasticnet;, score=-3.264 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.01, loss=huber, penalty=elasticnet;, score=-5.017 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l1;, score=-2.037 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l1;, score=-5.846 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l1;, score=-2.176 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l1;, score=-3.223 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l1;, score=-4.947 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l2;, score=-2.045 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l2;, score=-5.873 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l2;, score=-2.188 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l2;, score=-3.237 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.01, loss=epsilon_insensitive, penalty=l2;, score=-4.970 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.01, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.044 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.01, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.870 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.01, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.186 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.01, loss=epsilon_insensitive, penalty=elasticnet;, score=-3.235 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.01, loss=epsilon_insensitive, penalty=elasticnet;, score=-4.968 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l1;, score=-24921685258.857 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l1;, score=-282630848531.919 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l1;, score=-10279471750.735 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l1;, score=-5459777993.038 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l1;, score=-18327419391.737 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l2;, score=-11832630594.276 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l2;, score=-21282141369.900 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l2;, score=-20360530492.726 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l2;, score=-15329348981.318 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=l2;, score=-30237389001.121 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-21489957024.865 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-8477318405.376 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-3549757890.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-11862938408.291 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.01, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-269396449906.394 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_error, penalty=l1;, score=-37672689737.535 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_error, penalty=l1;, score=-2998661204.179 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_error, penalty=l1;, score=-15751350206.116 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_error, penalty=l1;, score=-27531450919.154 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_error, penalty=l1;, score=-6250160988.024 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_error, penalty=l2;, score=-2561585006.683 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_error, penalty=l2;, score=-357435521731.742 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_error, penalty=l2;, score=-807970744485.997 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_error, penalty=l2;, score=-5131389677.908 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_error, penalty=l2;, score=-2814452029.649 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_error, penalty=elasticnet;, score=-18147761038.585 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_error, penalty=elasticnet;, score=-36546623259.186 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_error, penalty=elasticnet;, score=-5759576698.161 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_error, penalty=elasticnet;, score=-1900629054.416 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_error, penalty=elasticnet;, score=-69743275675.474 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=huber, penalty=l1;, score=-2.062 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.1, loss=huber, penalty=l1;, score=-5.927 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.1, loss=huber, penalty=l1;, score=-2.212 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=0.1, loss=huber, penalty=l1;, score=-3.264 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.1, loss=huber, penalty=l1;, score=-5.017 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.1, loss=huber, penalty=l2;, score=-2.064 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=0.1, loss=huber, penalty=l2;, score=-5.932 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=huber, penalty=l2;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=huber, penalty=l2;, score=-3.267 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.1, loss=huber, penalty=l2;, score=-5.022 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=huber, penalty=elasticnet;, score=-2.064 total time=   0.1s\n",
            "[CV 2/5] END alpha=0.1, loss=huber, penalty=elasticnet;, score=-5.932 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.1, loss=huber, penalty=elasticnet;, score=-2.215 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.1, loss=huber, penalty=elasticnet;, score=-3.267 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.1, loss=huber, penalty=elasticnet;, score=-5.022 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l1;, score=-2.037 total time=   0.1s\n",
            "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l1;, score=-5.849 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l1;, score=-2.177 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l1;, score=-3.224 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l1;, score=-4.949 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l2;, score=-2.060 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l2;, score=-5.922 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l2;, score=-2.210 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l2;, score=-3.262 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, penalty=l2;, score=-5.013 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.060 total time=   0.1s\n",
            "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.920 total time=   0.1s\n",
            "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.209 total time=   0.1s\n",
            "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, penalty=elasticnet;, score=-3.261 total time=   0.1s\n",
            "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.011 total time=   0.1s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l1;, score=-14378172598.646 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l1;, score=-337674299206.417 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l1;, score=-1517183832.111 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l1;, score=-37916392792.640 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l1;, score=-17454614570.511 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l2;, score=-6194977053.176 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l2;, score=-38384612112.918 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l2;, score=-144797706835.116 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l2;, score=-159041829421.308 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=l2;, score=-41244596305.038 total time=   0.0s\n",
            "[CV 1/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-4942635111.388 total time=   0.0s\n",
            "[CV 2/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-108142644944.495 total time=   0.0s\n",
            "[CV 3/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-28491167155.569 total time=   0.0s\n",
            "[CV 4/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-22874118691.145 total time=   0.0s\n",
            "[CV 5/5] END alpha=0.1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-38530159577.337 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_error, penalty=l1;, score=-215062645146.286 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_error, penalty=l1;, score=-3486059673.915 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_error, penalty=l1;, score=-14283784424.469 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_error, penalty=l1;, score=-5520185521.943 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_error, penalty=l1;, score=-7973796796.005 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_error, penalty=l2;, score=-1425223101.625 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_error, penalty=l2;, score=-11415503544.176 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_error, penalty=l2;, score=-41432078.142 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_error, penalty=l2;, score=-9378719063.533 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_error, penalty=l2;, score=-11237213162.925 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_error, penalty=elasticnet;, score=-5565412656.303 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_error, penalty=elasticnet;, score=-19989620036.618 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_error, penalty=elasticnet;, score=-920967056.134 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_error, penalty=elasticnet;, score=-8940901578.410 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_error, penalty=elasticnet;, score=-8642197235.901 total time=   0.0s\n",
            "[CV 1/5] END ..alpha=1, loss=huber, penalty=l1;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END ..alpha=1, loss=huber, penalty=l1;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END ..alpha=1, loss=huber, penalty=l1;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END ..alpha=1, loss=huber, penalty=l1;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END ..alpha=1, loss=huber, penalty=l1;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END ..alpha=1, loss=huber, penalty=l2;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END ..alpha=1, loss=huber, penalty=l2;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END ..alpha=1, loss=huber, penalty=l2;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END ..alpha=1, loss=huber, penalty=l2;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END ..alpha=1, loss=huber, penalty=l2;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=huber, penalty=elasticnet;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=huber, penalty=elasticnet;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=huber, penalty=elasticnet;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=huber, penalty=elasticnet;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=huber, penalty=elasticnet;, score=-5.023 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END alpha=1, loss=epsilon_insensitive, penalty=l1;, score=-2.044 total time=   0.1s\n",
            "[CV 2/5] END alpha=1, loss=epsilon_insensitive, penalty=l1;, score=-5.869 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END alpha=1, loss=epsilon_insensitive, penalty=l1;, score=-2.187 total time=   0.1s\n",
            "[CV 4/5] END alpha=1, loss=epsilon_insensitive, penalty=l1;, score=-3.235 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END alpha=1, loss=epsilon_insensitive, penalty=l1;, score=-4.968 total time=   0.1s\n",
            "[CV 1/5] END alpha=1, loss=epsilon_insensitive, penalty=l2;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=epsilon_insensitive, penalty=l2;, score=-5.932 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=epsilon_insensitive, penalty=l2;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=epsilon_insensitive, penalty=l2;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=epsilon_insensitive, penalty=l2;, score=-5.022 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.932 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=epsilon_insensitive, penalty=elasticnet;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.022 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l1;, score=-95399494840.294 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l1;, score=-13513452647.245 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l1;, score=-24146346885.741 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l1;, score=-1013540954.299 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l1;, score=-115942319983.476 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l2;, score=-9367025269.651 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l2;, score=-32123014019.108 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l2;, score=-238811469770.736 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l2;, score=-7123964200.543 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=l2;, score=-75362366206.562 total time=   0.0s\n",
            "[CV 1/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-26128450678.371 total time=   0.0s\n",
            "[CV 2/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-116660113415.759 total time=   0.0s\n",
            "[CV 3/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-1769654724.012 total time=   0.0s\n",
            "[CV 4/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-1998462515.764 total time=   0.0s\n",
            "[CV 5/5] END alpha=1, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-10335376554.390 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_error, penalty=l1;, score=-40621092054.444 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_error, penalty=l1;, score=-29807697451.942 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_error, penalty=l1;, score=-6537418345.821 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_error, penalty=l1;, score=-107404765111.079 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_error, penalty=l1;, score=-38632917856.226 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_error, penalty=l2;, score=-2484759216.182 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_error, penalty=l2;, score=-251806026.338 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_error, penalty=l2;, score=-690000.463 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_error, penalty=l2;, score=-755340746.336 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_error, penalty=l2;, score=-467.821 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_error, penalty=elasticnet;, score=-840808355.231 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_error, penalty=elasticnet;, score=-21022080081.595 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_error, penalty=elasticnet;, score=-139043111.115 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_error, penalty=elasticnet;, score=-2902021101.309 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_error, penalty=elasticnet;, score=-51953426.195 total time=   0.0s\n",
            "[CV 1/5] END .alpha=10, loss=huber, penalty=l1;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END .alpha=10, loss=huber, penalty=l1;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END .alpha=10, loss=huber, penalty=l1;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END .alpha=10, loss=huber, penalty=l1;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END .alpha=10, loss=huber, penalty=l1;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END .alpha=10, loss=huber, penalty=l2;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END .alpha=10, loss=huber, penalty=l2;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END .alpha=10, loss=huber, penalty=l2;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END .alpha=10, loss=huber, penalty=l2;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END .alpha=10, loss=huber, penalty=l2;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=huber, penalty=elasticnet;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=huber, penalty=elasticnet;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=huber, penalty=elasticnet;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=huber, penalty=elasticnet;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=huber, penalty=elasticnet;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=epsilon_insensitive, penalty=l1;, score=-2.064 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=10, loss=epsilon_insensitive, penalty=l1;, score=-5.933 total time=   0.1s\n",
            "[CV 3/5] END alpha=10, loss=epsilon_insensitive, penalty=l1;, score=-2.215 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END alpha=10, loss=epsilon_insensitive, penalty=l1;, score=-3.267 total time=   0.1s\n",
            "[CV 5/5] END alpha=10, loss=epsilon_insensitive, penalty=l1;, score=-5.022 total time=   0.1s\n",
            "[CV 1/5] END alpha=10, loss=epsilon_insensitive, penalty=l2;, score=-2.064 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=epsilon_insensitive, penalty=l2;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=epsilon_insensitive, penalty=l2;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=epsilon_insensitive, penalty=l2;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=epsilon_insensitive, penalty=l2;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.064 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END alpha=10, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.933 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=epsilon_insensitive, penalty=elasticnet;, score=-2.215 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=epsilon_insensitive, penalty=elasticnet;, score=-3.267 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=epsilon_insensitive, penalty=elasticnet;, score=-5.023 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l1;, score=-2998157344.342 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l1;, score=-25575453705.385 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l1;, score=-15003929540.704 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l1;, score=-5340287470.690 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l1;, score=-203168054784.186 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l2;, score=-1384810184.694 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l2;, score=-487548932.995 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l2;, score=-533544907.144 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l2;, score=-114997239657.510 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=l2;, score=-6108864715.273 total time=   0.0s\n",
            "[CV 1/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-212653330050.498 total time=   0.0s\n",
            "[CV 2/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-8397161172.292 total time=   0.0s\n",
            "[CV 3/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-34667729399.553 total time=   0.0s\n",
            "[CV 4/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-969765788.487 total time=   0.0s\n",
            "[CV 5/5] END alpha=10, loss=squared_epsilon_insensitive, penalty=elasticnet;, score=-3824870392.193 total time=   0.0s\n",
            "{'alpha': 0.01, 'loss': 'epsilon_insensitive', 'penalty': 'l1'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'penalty': 'l1', 'loss': 'epsilon_insensitive', 'alpha': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Constructing SGD Regressor with the Best Params\n",
        "\n",
        "reg5_grid_search = make_pipeline(StandardScaler(), SGDRegressor(**grid_parm_sgd))\n",
        "reg5_grid_search.fit(Xtrain, Y)\n",
        "sgd_test_prediction_grid_search = reg5_grid_search.predict(XTest)\n",
        "print(reg5_grid_search.predict(XTest))\n",
        "\n",
        "reg5_grid_random = make_pipeline(StandardScaler(), SGDRegressor(**random_parm_sgd))\n",
        "reg5_grid_random.fit(Xtrain, Y)\n",
        "sgd_test_prediction_random_search = reg5_grid_random.predict(XTest)\n",
        "print(reg5_grid_random.predict(XTest))\n",
        "\n",
        "\n",
        "#Writing the Predictions to CSV file\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "\n",
        "sgd_predictions_random = pd.DataFrame({\"Id\":testData_id, \"Prediction\":sgd_test_prediction_random_search})  \n",
        "sgd_predictions_random.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/SGD_Random_Submission.csv',index=None)\n",
        "\n",
        "sgd_predictions_grid = pd.DataFrame({\"Id\":testData_id, \"Prediction\":sgd_test_prediction_grid_search})  \n",
        "sgd_predictions_grid.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/SGD_Grid_Submission.csv',index=None)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYOxTe8ia9vj",
        "outputId": "e4eb8ec4-2f2a-4faf-805e-371785665b69"
      },
      "id": "nYOxTe8ia9vj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[94.93867126 94.93867126 94.93867126 ... 94.93867126 94.93867126\n",
            " 94.93867126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1507: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[94.93867126 94.93867126 94.93867126 ... 94.93867126 94.93867126\n",
            " 94.93867126]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ***ENSEMBLE METHODS STACKING***\n",
        "\n",
        "#Model 1\n",
        "\n",
        "print(\"\\n Ensemble Methods Predictions using MLP, SVR, RandomForest\\n\")\n",
        "\n",
        "models = [ regr1, regr2, regr4]\n",
        "      \n",
        "S_Train, S_Test = stacking(models,                   \n",
        "                           Xtrain, Y, XTest,   \n",
        "                           regression=True, \n",
        "     \n",
        "                           mode='oof_pred_bag', \n",
        "       \n",
        "                           needs_proba=False,\n",
        "         \n",
        "                           save_dir=None, \n",
        "            \n",
        "                           metric=mean_squared_error, \n",
        "    \n",
        "                           n_folds=5, \n",
        "                 \n",
        "                           stratified=False,\n",
        "            \n",
        "                           shuffle=True,  \n",
        "            \n",
        "                           random_state=0,    \n",
        "         \n",
        "                           verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxw2AN31qXda",
        "outputId": "a848d65c-5d1b-4db7-da9b-1edd10fc230b"
      },
      "id": "Hxw2AN31qXda",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ensemble Methods Predictions using MLP, SVR, RandomForest\n",
            "\n",
            "task:         [regression]\n",
            "metric:       [mean_squared_error]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [RandomForestRegressor]\n",
            "    fold  0:  [9998982028219.36132812]\n",
            "    fold  1:  [5020467786928.10449219]\n",
            "    fold  2:  [5058852800675.19433594]\n",
            "    fold  3:  [11612874379737.11132812]\n",
            "    fold  4:  [5362227120717.17871094]\n",
            "    ----\n",
            "    MEAN:     [7410680823255.39062500] + [2821280198492.14306641]\n",
            "    FULL:     [7412126722296.53320312]\n",
            "\n",
            "model  1:     [SVR]\n",
            "    fold  0:  [11981207454607.70312500]\n",
            "    fold  1:  [3078628644064.07666016]\n",
            "    fold  2:  [3344291986247.65869141]\n",
            "    fold  3:  [13277890486023.03320312]\n",
            "    fold  4:  [2867612241023.52148438]\n",
            "    ----\n",
            "    MEAN:     [6909926162393.19824219] + [4690453137229.66992188]\n",
            "    FULL:     [6918977138844.91601562]\n",
            "\n",
            "model  2:     [MLPRegressor]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold  0:  [34744017077757.28125000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold  1:  [17796103012675.27734375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold  2:  [21798036697128.04296875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold  3:  [38167451457610.40625000]\n",
            "    fold  4:  [16935853814272.08398438]\n",
            "    ----\n",
            "    MEAN:     [25888292411888.61718750] + [8849423531019.09765625]\n",
            "    FULL:     [25893865662010.19140625]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting MLP Regressor into Stacked Train Data Set\n",
        "\n",
        "mlp_StackedModel = MLPRegressor()\n",
        "mlp_StackedModel.fit(S_Train, Y)\n",
        "\n",
        "#Predicting the Stacked Test Data Set\n",
        "mlp_predict_stacked=mlp_StackedModel.predict(S_Test)\n",
        "print(mlp_StackedModel.predict(S_Test))\n",
        "\n",
        "#Hyper Parameter Tuning of the Stacked Model (MLP since it had the best score)\n",
        "\n",
        "#Random Search\n",
        "print(\"RandomizedSearchCV - MLP Regressor\")\n",
        "rand_parameters = {'learning_rate' : ['adaptive', 'constant', 'invscaling'], 'activation' : ['logistic', 'relu', 'identity'], 'solver': ['lbfgs', 'sgd']}\n",
        "\n",
        "mlp_random_stacked = RandomizedSearchCV(mlp_StackedModel,rand_parameters,n_iter=3,cv=5)\n",
        "mlp_random_stacked.fit(S_Train, Y)\n",
        "random_parm_stacked=mlp_random_stacked.best_params_\n",
        "print(random_parm_stacked)\n",
        "\n",
        "#Grid Search\n",
        "print(\"GridSearchCV - MLP Regressor\")\n",
        "\n",
        "mlp_grid_stacked = GridSearchCV(mlp_StackedModel,rand_parameters,cv=5)\n",
        "mlp_grid_stacked.fit(S_Train, Y)\n",
        "grid_parm_stacked=mlp_grid_stacked.best_params_\n",
        "print(grid_parm_stacked)\n",
        "\n",
        "#Using the best parameters to construct a MLP Regressor\n",
        "mlprRand_stacked = MLPRegressor(**random_parm_stacked)\n",
        "mlprGrid_stacked = MLPRegressor(**grid_parm_stacked)\n",
        "\n",
        "mlprRand_stacked.fit(S_Train,Y)\n",
        "mlprRand_stacked_predict = mlprRand_stacked.predict(S_Test)\n",
        "\n",
        "mlprGrid_stacked.fit(S_Train,Y)\n",
        "mlprGrid_stacked_predict = mlprGrid_stacked.predict(S_Test)\n",
        "\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "mlpr_prediction_random_stacked = pd.DataFrame({\"Id\":testData_id, \"Prediction\":mlprRand_stacked_predict})\n",
        "mlpr_prediction_grid_stacked = pd.DataFrame({\"Id\":testData_id, \"Prediction\":mlprGrid_stacked_predict})\n",
        "\n",
        "mlpr_prediction_random_stacked.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/MLP_Random_Stacked.csv',index=None)\n",
        "mlpr_prediction_grid_stacked.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/MLP_Grid_Stacked.csv',index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VluFFF_WxRgn",
        "outputId": "bce8deb1-9cf2-42fd-ec89-59c7250fe600"
      },
      "id": "VluFFF_WxRgn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4149491.21373777 4484330.25951089 4048224.02963532 ... 4570211.61478768\n",
            " 4538740.8315592  4546283.90607817]\n",
            "RandomizedSearchCV - MLP Regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [            nan -4.65036179e-02 -3.62684139e+38]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'solver': 'lbfgs', 'learning_rate': 'constant', 'activation': 'logistic'}\n",
            "GridSearchCV - MLP Regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 706, in score\n",
            "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 790, in r2_score\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 96, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-2.10220827e-01 -2.00955187e-02 -1.13453878e-01 -2.42542915e-02\n",
            " -1.26804555e-01 -6.90580750e-02  1.38265558e-02 -3.73021328e+38\n",
            "  1.03209884e-02 -2.50827524e+38  1.16629958e-02 -2.85492231e+36\n",
            " -3.19010158e-02             nan -3.19011446e-02             nan\n",
            " -3.19018507e-02             nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ***ENSEMBLE METHODS STACKING***\n",
        "\n",
        "#Model 2\n",
        "\n",
        "print(\"\\n Ensemble Methods Predictions using Decision Tree, SGD, RandomForest\\n\")\n",
        "\n",
        "models1 = [ regr1, regr3, reg5]\n",
        "      \n",
        "S_Train1, S_Test1 = stacking(models1,                   \n",
        "                           Xtrain, Y, XTest,   \n",
        "                           regression=True, \n",
        "     \n",
        "                           mode='oof_pred_bag', \n",
        "       \n",
        "                           needs_proba=False,\n",
        "         \n",
        "                           save_dir=None, \n",
        "            \n",
        "                           metric=mean_squared_error, \n",
        "    \n",
        "                           n_folds=7, \n",
        "                 \n",
        "                           stratified=False,\n",
        "            \n",
        "                           shuffle=True,  \n",
        "            \n",
        "                           random_state=0,    \n",
        "         \n",
        "                           verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNba4BHl_Mgz",
        "outputId": "c3330057-c6b7-4a1e-a0b8-702c52a816bd"
      },
      "id": "lNba4BHl_Mgz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ensemble Methods Predictions using Decision Tree, SGD, RandomForest\n",
            "\n",
            "task:         [regression]\n",
            "metric:       [mean_squared_error]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [RandomForestRegressor]\n",
            "    fold  0:  [4628060015085.91601562]\n",
            "    fold  1:  [14255802207898.24609375]\n",
            "    fold  2:  [2689356229658.98974609]\n",
            "    fold  3:  [4150719906428.93652344]\n",
            "    fold  4:  [9564181042721.33789062]\n",
            "    fold  5:  [8611745580505.67968750]\n",
            "    fold  6:  [3938852842976.31152344]\n",
            "    ----\n",
            "    MEAN:     [6834102546467.91699219] + [3841940137409.03125000]\n",
            "    FULL:     [6822332679119.01562500]\n",
            "\n",
            "model  1:     [DecisionTreeRegressor]\n",
            "    fold  0:  [12000155137315.09960938]\n",
            "    fold  1:  [20298349716049.60156250]\n",
            "    fold  2:  [2368586252908.70019531]\n",
            "    fold  3:  [8877199593409.69921875]\n",
            "    fold  4:  [15728744996254.26367188]\n",
            "    fold  5:  [11352401212300.63085938]\n",
            "    fold  6:  [4122773305958.26318359]\n",
            "    ----\n",
            "    MEAN:     [10678315744885.18164062] + [5800545542270.80078125]\n",
            "    FULL:     [10684381640652.64257812]\n",
            "\n",
            "model  2:     [Pipeline]\n",
            "    fold  0:  [23436204943409.89843750]\n",
            "    fold  1:  [19646997631486.32031250]\n",
            "    fold  2:  [17189820243160.05078125]\n",
            "    fold  3:  [10242810936648.16406250]\n",
            "    fold  4:  [12469945434070.60351562]\n",
            "    fold  5:  [12275732887834.90625000]\n",
            "    fold  6:  [8495192279387.60351562]\n",
            "    ----\n",
            "    MEAN:     [14822386336571.08007812] + [5015758109757.22558594]\n",
            "    FULL:     [14904330047581.44531250]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting Random Forest into Stacked Train Data Set\n",
        "\n",
        "rfr_StackedModel = RandomForestRegressor()\n",
        "rfr_StackedModel.fit(S_Train, Y)\n",
        "\n",
        "#Predicting the Stacked Test Data Set\n",
        "rfr_predict_stacked=rfr_StackedModel.predict(S_Test)\n",
        "print(rfr_StackedModel.predict(S_Test))\n",
        "\n",
        "#Hyper Parameter Tuning of the Stacked Model (Random Forest since it had the best score)\n",
        "\n",
        "#Random Search\n",
        "print(\"RandomSearchCV - Random Forest\")\n",
        "rand_parameters_stacked={'min_samples_leaf' : range(10,200,20),'max_depth': \n",
        "            range(1,50,6), 'max_leaf_nodes': \n",
        "            range(1,75,8)}\n",
        "\n",
        "rfr_random_stacked = RandomizedSearchCV(rfr_StackedModel,rand_parameters_stacked,n_iter=5,cv=5)\n",
        "rfr_random_stacked.fit(S_Train, Y)\n",
        "random_parm_rfr_stacked=rfr_random_stacked.best_params_\n",
        "print(random_parm_rfr_stacked)\n",
        "\n",
        "#Grid Search\n",
        "print(\"GridSearchCV - Random Forest\")\n",
        "\n",
        "rfr_grid_stacked = GridSearchCV(rfr_StackedModel,rand_parameters_stacked,cv=5)\n",
        "rfr_grid_stacked.fit(S_Train, Y)\n",
        "rfr_grid_parm_stacked=rfr_grid_stacked.best_params_\n",
        "print(rfr_grid_parm_stacked)\n",
        "\n",
        "#Using the best parameters to construct a Random Forest Regressor\n",
        "rfrRand_stacked = RandomForestRegressor(**random_parm_rfr_stacked)\n",
        "rfrGrid_stacked = RandomForestRegressor(**rfr_grid_parm_stacked)\n",
        "\n",
        "rfrRand_stacked.fit(S_Train,Y)\n",
        "rfrRand_stacked_predict = rfrRand_stacked.predict(S_Test)\n",
        "\n",
        "rfrGrid_stacked.fit(S_Train,Y)\n",
        "rfrGrid_stacked_predict = rfrGrid_stacked.predict(S_Test)\n",
        "\n",
        "testData_id = test_df_original.Id\n",
        "\n",
        "rfr_prediction_random_stacked = pd.DataFrame({\"Id\":testData_id, \"Prediction\":rfrRand_stacked_predict})\n",
        "rfr_prediction_grid_stacked = pd.DataFrame({\"Id\":testData_id, \"Prediction\":rfrGrid_stacked_predict})\n",
        "\n",
        "mlpr_prediction_random_stacked.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/RFR_Random_Stacked.csv',index=None)\n",
        "mlpr_prediction_grid_stacked.to_csv(r'/gdrive/My Drive/Team_Assignment_1/Submissions/RFR_Grid_Stacked.csv',index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvQCTVegCFly",
        "outputId": "999cab83-4ce3-4cf3-cc1a-9ae795287964"
      },
      "id": "yvQCTVegCFly",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4499807.71 4499808.61 6272150.63 ... 5693367.06 6159165.   4980974.21]\n",
            "RandomSearchCV - Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "5 fits failed out of a total of 25.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 316, in fit\n",
            "    max_leaf_nodes\n",
            "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.01672338 -0.06810237         nan -0.01827788 -0.01609074]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_samples_leaf': 110, 'max_leaf_nodes': 57, 'max_depth': 7}\n",
            "GridSearchCV - Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "450 fits failed out of a total of 4500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "450 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 316, in fit\n",
            "    max_leaf_nodes\n",
            "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan  0.00892857 -0.03151947\n",
            " -0.01656203 -0.01835164 -0.01580298 -0.01545514 -0.01582964 -0.01809496\n",
            " -0.0159863  -0.01549989  0.01380611 -0.03202156 -0.01781071 -0.0178076\n",
            " -0.01838171 -0.01640556 -0.01613912 -0.0158942  -0.01527976 -0.01610071\n",
            "  0.00644126 -0.02963128 -0.01847563 -0.01614956 -0.01718512 -0.01621588\n",
            " -0.01801876 -0.01739594 -0.01540569 -0.01661375  0.01648931 -0.02188182\n",
            " -0.01804104 -0.01620664 -0.01686445 -0.01698297 -0.01606423 -0.01599424\n",
            " -0.01523198 -0.01731445  0.01000196 -0.02450882 -0.01804896 -0.0178141\n",
            " -0.01529914 -0.01604749 -0.01755246 -0.01942706 -0.01668404 -0.01614123\n",
            "  0.01797476 -0.03412802 -0.01627007 -0.0172601  -0.01724662 -0.01751231\n",
            " -0.01661644 -0.01616759 -0.0163689  -0.01864101  0.01218097 -0.03568547\n",
            " -0.01707849 -0.01798579 -0.01812571 -0.01655795 -0.01619651 -0.01680379\n",
            " -0.01787762 -0.01676176  0.01339436 -0.022451   -0.01640729 -0.01692411\n",
            " -0.0193487  -0.01665198 -0.01797677 -0.01967109 -0.01699146 -0.01696393\n",
            "  0.01972807 -0.03478917 -0.01788338 -0.01708487 -0.01702306 -0.01569318\n",
            " -0.01641918 -0.01912851 -0.01873319 -0.01748782         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan -0.0733135  -0.01748181 -0.01684995 -0.01814757\n",
            " -0.01713152 -0.01759757 -0.01849819 -0.01815349 -0.01830438 -0.01493971\n",
            " -0.06024764 -0.02734254 -0.015934   -0.01713354 -0.01732763 -0.01540256\n",
            " -0.0169702  -0.01728954 -0.01666863 -0.01849764 -0.06086941 -0.02303307\n",
            " -0.01651094 -0.01952609 -0.01571985 -0.01821282 -0.01597251 -0.01634511\n",
            " -0.01675973 -0.01755115 -0.06065373 -0.03573302 -0.01803567 -0.01680626\n",
            " -0.01686495 -0.01731872 -0.01827828 -0.01760977 -0.01762943 -0.01770844\n",
            " -0.0450832  -0.0394536  -0.01748672 -0.01737497 -0.01654276 -0.0185772\n",
            " -0.01606157 -0.0184937  -0.01669087 -0.01869025 -0.07810433 -0.02907732\n",
            " -0.01666953 -0.01821734 -0.01805593 -0.01679073 -0.01624778 -0.01928716\n",
            " -0.01735485 -0.01686505 -0.04645957 -0.03585114 -0.01700409 -0.01819389\n",
            " -0.01805793 -0.01740326 -0.0180786  -0.01828114 -0.0167216  -0.01727372\n",
            " -0.05975686 -0.02892558 -0.02015791 -0.01731923 -0.01774362 -0.01754886\n",
            " -0.01675318 -0.01645793 -0.01742991 -0.01689963 -0.06406589 -0.04088038\n",
            " -0.01645316 -0.01729323 -0.01735554 -0.01705528 -0.01593325 -0.01903973\n",
            " -0.01593005 -0.01778872         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.06416413 -0.03436197 -0.01569471 -0.01799989 -0.01767744 -0.01623292\n",
            " -0.01651954 -0.01757286 -0.01865981 -0.01688558 -0.06742688 -0.02597034\n",
            " -0.01458885 -0.01729727 -0.01827127 -0.0167148  -0.01702152 -0.01794526\n",
            " -0.01666648 -0.01653993 -0.08361964 -0.03046329 -0.01729565 -0.01692646\n",
            " -0.01564197 -0.01718756 -0.01980235 -0.01614831 -0.01760622 -0.01697264\n",
            " -0.07135857 -0.03460642 -0.01798489 -0.01663588 -0.01587743 -0.01696717\n",
            " -0.01574214 -0.01820338 -0.01849668 -0.01828293 -0.06952444 -0.0297109\n",
            " -0.02021728 -0.01748896 -0.01788561 -0.01581682 -0.01764487 -0.01703199\n",
            " -0.01662588 -0.01740425 -0.07994258 -0.02410277 -0.01737736 -0.01893988\n",
            " -0.01631606 -0.01682066 -0.01776606 -0.0158056  -0.01561049 -0.01940955\n",
            " -0.04440387 -0.02760473 -0.01846606 -0.01743381 -0.01668606 -0.01539471\n",
            " -0.01717965 -0.01620506 -0.01554442 -0.01618023 -0.07536004 -0.03209792\n",
            " -0.01636734 -0.01960623 -0.01623661 -0.01681887 -0.01665907 -0.01722733\n",
            " -0.0190547  -0.01510743 -0.06713791 -0.02866469 -0.01608735 -0.0160981\n",
            " -0.01878645 -0.01687674 -0.0162927  -0.01746995 -0.0171213  -0.01725158\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan -0.06174896 -0.03311929\n",
            " -0.01825414 -0.01833769 -0.0180205  -0.01792252 -0.01833883 -0.01840784\n",
            " -0.01935916 -0.01810496 -0.06391629 -0.02622474 -0.01584306 -0.02034933\n",
            " -0.01656896 -0.01584851 -0.01653275 -0.01684978 -0.01863102 -0.01701102\n",
            " -0.05617346 -0.03269569 -0.01820051 -0.01634161 -0.0188517  -0.01668712\n",
            " -0.01675935 -0.01603659 -0.01757484 -0.01781582 -0.05904563 -0.03793096\n",
            " -0.01924014 -0.016588   -0.01589255 -0.01704614 -0.01855077 -0.01575286\n",
            " -0.01617217 -0.0178751  -0.04438709 -0.0335674  -0.01578442 -0.0162228\n",
            " -0.01659435 -0.01726983 -0.01685104 -0.01664681 -0.01571493 -0.01651682\n",
            " -0.07284283 -0.03538178 -0.0165074  -0.01629798 -0.01729426 -0.01723885\n",
            " -0.01656454 -0.01790853 -0.01712037 -0.01897423 -0.05278818 -0.02564939\n",
            " -0.0172508  -0.01753904 -0.01697318 -0.01668039 -0.01629116 -0.01746312\n",
            " -0.01716578 -0.01788501 -0.07672028 -0.03028581 -0.01674769 -0.017812\n",
            " -0.01522636 -0.01584905 -0.01727066 -0.01747022 -0.01794219 -0.01905456\n",
            " -0.06843362 -0.03389698 -0.01718928 -0.01735852 -0.01740154 -0.01715261\n",
            " -0.01613076 -0.01825364 -0.01869109 -0.01651433         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan -0.04682665 -0.0306337  -0.01572105 -0.01712567\n",
            " -0.01930656 -0.01759297 -0.01846179 -0.01591934 -0.01605245 -0.01785387\n",
            " -0.07192424 -0.03347491 -0.01558193 -0.01750056 -0.01673819 -0.01947882\n",
            " -0.0178591  -0.01672475 -0.01708931 -0.01709075 -0.0621818  -0.03174247\n",
            " -0.01682698 -0.01723583 -0.01837508 -0.01413619 -0.0172425  -0.01753998\n",
            " -0.01643266 -0.01845009 -0.05644442 -0.02925267 -0.01560792 -0.0173403\n",
            " -0.01788743 -0.01572724 -0.01811827 -0.01734509 -0.01733083 -0.01479613\n",
            " -0.06742257 -0.02764945 -0.01791818 -0.01674522 -0.0176062  -0.01639181\n",
            " -0.01702007 -0.01672396 -0.01777189 -0.01881984 -0.07053776 -0.03175299\n",
            " -0.01607214 -0.01705293 -0.01799482 -0.01674115 -0.01660322 -0.01751039\n",
            " -0.01711442 -0.01505918 -0.04711831 -0.02359803 -0.01717374 -0.01634144\n",
            " -0.01600058 -0.016542   -0.0187431  -0.01836691 -0.01857744 -0.01692182\n",
            " -0.06643051 -0.03166721 -0.01638877 -0.01723967 -0.01711019 -0.01740257\n",
            " -0.01706    -0.01838703 -0.01657206 -0.01879285 -0.05990227 -0.02698656\n",
            " -0.01789641 -0.01765723 -0.01691761 -0.01666471 -0.01534572 -0.01634906\n",
            " -0.01712529 -0.01766013         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.06638848 -0.03245541 -0.01813098 -0.01739121 -0.01650889 -0.01750817\n",
            " -0.01823316 -0.01805648 -0.01793337 -0.01640815 -0.07127314 -0.02283753\n",
            " -0.01822885 -0.01844172 -0.01771296 -0.01530011 -0.0192306  -0.01692697\n",
            " -0.01831398 -0.01762794 -0.05489676 -0.02923685 -0.01626654 -0.0159147\n",
            " -0.0151596  -0.0178773  -0.01742582 -0.0193104  -0.01943628 -0.01871842\n",
            " -0.05239566 -0.02104699 -0.01682721 -0.01793514 -0.01771945 -0.01692978\n",
            " -0.01641373 -0.01772839 -0.01741186 -0.01891174 -0.06350786 -0.02224755\n",
            " -0.01706885 -0.01732835 -0.01571469 -0.01580055 -0.01643985 -0.0177586\n",
            " -0.01560689 -0.01689682 -0.04682078 -0.03385865 -0.01593003 -0.01980075\n",
            " -0.01678158 -0.01635342 -0.01689027 -0.01765786 -0.01489088 -0.01592085\n",
            " -0.05920515 -0.04302614 -0.0194295  -0.01638155 -0.01720033 -0.01583727\n",
            " -0.01588333 -0.01676565 -0.01822559 -0.01630197 -0.05794453 -0.0226233\n",
            " -0.01548935 -0.01949179 -0.01908259 -0.01992966 -0.0151877  -0.01767129\n",
            " -0.01736684 -0.01614996 -0.06975438 -0.02996994 -0.01596049 -0.01797604\n",
            " -0.01577428 -0.01837405 -0.01612294 -0.01638522 -0.01650866 -0.01688767\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan -0.05783079 -0.02945425\n",
            " -0.01673542 -0.016881   -0.01728441 -0.01685669 -0.01787494 -0.01730351\n",
            " -0.01866953 -0.01637695 -0.06587377 -0.03095798 -0.0166137  -0.01811288\n",
            " -0.01680621 -0.01621926 -0.01708939 -0.01848876 -0.01808886 -0.01750892\n",
            " -0.06754002 -0.03215629 -0.01716172 -0.01598309 -0.01726494 -0.01779279\n",
            " -0.01684938 -0.0171571  -0.01846407 -0.01677931 -0.07657833 -0.02331569\n",
            " -0.01708    -0.01945849 -0.01895579 -0.01722286 -0.01846977 -0.0157997\n",
            " -0.0188015  -0.01627863 -0.06948872 -0.02558439 -0.01816478 -0.01562484\n",
            " -0.01720705 -0.01755718 -0.01666837 -0.01763082 -0.01806768 -0.01736043\n",
            " -0.05501944 -0.02882193 -0.01867939 -0.01783592 -0.0180735  -0.01726292\n",
            " -0.01554885 -0.01728465 -0.01699483 -0.01623129 -0.06110723 -0.02571382\n",
            " -0.01756866 -0.01731463 -0.01622822 -0.01832553 -0.01707325 -0.01719422\n",
            " -0.01687023 -0.01724966 -0.07195609 -0.03831965 -0.01654732 -0.01689134\n",
            " -0.01748253 -0.01587955 -0.01860568 -0.01635707 -0.01607858 -0.01705374\n",
            " -0.05848772 -0.01850501 -0.01699086 -0.01631981 -0.01790979 -0.0161398\n",
            " -0.01683342 -0.02028282 -0.01641719 -0.01624786         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan -0.06921705 -0.02757084 -0.0168739  -0.01668454\n",
            " -0.01936064 -0.01861352 -0.01860349 -0.01609044 -0.0160435  -0.01640261\n",
            " -0.05611477 -0.0342655  -0.01790366 -0.01668239 -0.01748163 -0.01780722\n",
            " -0.0165356  -0.01492718 -0.01809215 -0.0208243  -0.06498864 -0.02098573\n",
            " -0.01797874 -0.01626391 -0.01663899 -0.01571711 -0.01765962 -0.01694585\n",
            " -0.01787582 -0.01823206 -0.07033766 -0.04085037 -0.01882028 -0.01768954\n",
            " -0.01882384 -0.01714092 -0.01594874 -0.01625722 -0.01626533 -0.01556153\n",
            " -0.07777427 -0.02402214 -0.01809497 -0.0167346  -0.01691838 -0.01630179\n",
            " -0.01671489 -0.01815579 -0.01698858 -0.01946799 -0.0650628  -0.03023859\n",
            " -0.01538819 -0.01619087 -0.01848714 -0.01701552 -0.01631593 -0.01661443\n",
            " -0.01666756 -0.01773272 -0.06863641 -0.03193391 -0.01721503 -0.01679055\n",
            " -0.01608435 -0.01710178 -0.01794043 -0.01706222 -0.01729073 -0.01831379\n",
            " -0.05171178 -0.02471821 -0.0160596  -0.01601522 -0.01610486 -0.01494555\n",
            " -0.01808661 -0.01736102 -0.01738001 -0.01837727 -0.05910747 -0.02551529\n",
            " -0.01690449 -0.01644868 -0.01538528 -0.01660275 -0.0171892  -0.01692221\n",
            " -0.01586732 -0.01822391         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.06251669 -0.02492508 -0.0176423  -0.01830729 -0.01811299 -0.01771725\n",
            " -0.01666729 -0.01728742 -0.01828798 -0.01526311 -0.06703645 -0.02180694\n",
            " -0.01733125 -0.01773379 -0.01880279 -0.01929875 -0.01546608 -0.0179261\n",
            " -0.01638159 -0.01682601 -0.0727749  -0.03932576 -0.01546293 -0.02064263\n",
            " -0.01726963 -0.0165461  -0.01623432 -0.0168302  -0.01663105 -0.01574458\n",
            " -0.03976912 -0.02541821 -0.01628142 -0.01768203 -0.01807397 -0.01643381\n",
            " -0.01663852 -0.01762168 -0.01647636 -0.01641968 -0.06781012 -0.03209586\n",
            " -0.0187968  -0.01813127 -0.01608016 -0.01680627 -0.01663524 -0.01511873\n",
            " -0.01834004 -0.01624846 -0.07038603 -0.03417189 -0.0172914  -0.01826154\n",
            " -0.01797839 -0.01711266 -0.01816225 -0.01697911 -0.01614053 -0.01684307\n",
            " -0.05868284 -0.01959815 -0.01656602 -0.01700276 -0.01696077 -0.01588187\n",
            " -0.01616177 -0.01699805 -0.01699306 -0.01662493 -0.07251931 -0.03453511\n",
            " -0.01754229 -0.01801478 -0.01752362 -0.01701154 -0.01635522 -0.01636523\n",
            " -0.01539698 -0.01748663 -0.06904446 -0.03299906 -0.0170365  -0.01800149\n",
            " -0.01631832 -0.01755398 -0.01753805 -0.01498669 -0.0168976  -0.01552456]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 1, 'max_leaf_nodes': 73, 'min_samples_leaf': 10}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}